{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "Hello Daiana!\n\nI\u2019m happy to review your project today.\nI will mark your mistakes and give you some hints how it is possible to fix them. We are getting ready for real job, where your team leader/senior colleague will do exactly the same. Don't worry and study with pleasure!\n\nBelow you will find my comments - **please do not move, modify or delete them**.\n\nYou can find my comments in green, yellow or red boxes like this:\n\n<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n\nSuccess. Everything is done succesfully.\n</div>\n\n<div class=\"alert alert-block alert-warning\">\n<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n\nRemarks. Some recommendations.\n</div>\n\n<div class=\"alert alert-block alert-danger\">\n\n<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n\nNeeds fixing. The block requires some corrections. Work can't be accepted with the red comments.\n</div>\n\nYou can answer me by using this:\n\n<div class=\"alert alert-block alert-info\">\n<b>Student answer.</b> <a class=\"tocSkip\"></a>\n\nText here.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.     \n\nDevelop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset:\n\n1. Open and look through the data file.(data already preprocessed)\n2. Split the source data into a training set, a validation set, and a test set.\n3. Investigate the quality of different models by changing hyperparameters.\n4. Check the quality of the model using the test set.\n5. sanity check the model."}, {"cell_type": "code", "execution_count": 57, "metadata": {"trusted": false}, "outputs": [], "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression"}, {"cell_type": "markdown", "metadata": {}, "source": "# 1. Open and look through the data file."}, {"cell_type": "code", "execution_count": 4, "metadata": {"trusted": false}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>calls</th>\n      <th>minutes</th>\n      <th>messages</th>\n      <th>mb_used</th>\n      <th>is_ultra</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.0</td>\n      <td>311.90</td>\n      <td>83.0</td>\n      <td>19915.42</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85.0</td>\n      <td>516.75</td>\n      <td>56.0</td>\n      <td>22696.96</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>77.0</td>\n      <td>467.66</td>\n      <td>86.0</td>\n      <td>21060.45</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.0</td>\n      <td>745.53</td>\n      <td>81.0</td>\n      <td>8437.39</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>66.0</td>\n      <td>418.74</td>\n      <td>1.0</td>\n      <td>14502.75</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   calls  minutes  messages   mb_used  is_ultra\n0   40.0   311.90      83.0  19915.42         0\n1   85.0   516.75      56.0  22696.96         0\n2   77.0   467.66      86.0  21060.45         0\n3  106.0   745.53      81.0   8437.39         1\n4   66.0   418.74       1.0  14502.75         0"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "df = pd.read_csv('users_behavior.csv')\ndf.head()"}, {"cell_type": "code", "execution_count": 6, "metadata": {"trusted": false}, "outputs": [{"data": {"text/plain": "(3214, 5)"}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": "df.shape"}, {"cell_type": "code", "execution_count": 7, "metadata": {"trusted": false}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>calls</th>\n      <th>minutes</th>\n      <th>messages</th>\n      <th>mb_used</th>\n      <th>is_ultra</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3214.000000</td>\n      <td>3214.000000</td>\n      <td>3214.000000</td>\n      <td>3214.000000</td>\n      <td>3214.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>63.038892</td>\n      <td>438.208787</td>\n      <td>38.281269</td>\n      <td>17207.673836</td>\n      <td>0.306472</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>33.236368</td>\n      <td>234.569872</td>\n      <td>36.148326</td>\n      <td>7570.968246</td>\n      <td>0.461100</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>40.000000</td>\n      <td>274.575000</td>\n      <td>9.000000</td>\n      <td>12491.902500</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>62.000000</td>\n      <td>430.600000</td>\n      <td>30.000000</td>\n      <td>16943.235000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>82.000000</td>\n      <td>571.927500</td>\n      <td>57.000000</td>\n      <td>21424.700000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>244.000000</td>\n      <td>1632.060000</td>\n      <td>224.000000</td>\n      <td>49745.730000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "             calls      minutes     messages       mb_used     is_ultra\ncount  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\nmean     63.038892   438.208787    38.281269  17207.673836     0.306472\nstd      33.236368   234.569872    36.148326   7570.968246     0.461100\nmin       0.000000     0.000000     0.000000      0.000000     0.000000\n25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n75%      82.000000   571.927500    57.000000  21424.700000     1.000000\nmax     244.000000  1632.060000   224.000000  49745.730000     1.000000"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "df.describe()"}, {"cell_type": "code", "execution_count": 8, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3214 entries, 0 to 3213\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   calls     3214 non-null   float64\n 1   minutes   3214 non-null   float64\n 2   messages  3214 non-null   float64\n 3   mb_used   3214 non-null   float64\n 4   is_ultra  3214 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 125.7 KB\n"}], "source": "df.info()"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment V1</b>\n\nCorrect\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "# 2. Split the source data into a training set, a validation set, and a test set."}, {"cell_type": "code", "execution_count": 13, "metadata": {"trusted": false}, "outputs": [], "source": "train_set, valid = train_test_split(df, test_size=0.4, random_state=12345)\nvalid_set, test_set = train_test_split(valid, test_size=0.5, random_state=12345)\n# train_set, valid_set, test_set"}, {"cell_type": "code", "execution_count": 16, "metadata": {"trusted": false}, "outputs": [{"data": {"text/plain": "(1928, 5)"}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/plain": "(643, 5)"}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/plain": "(643, 5)"}, "metadata": {}, "output_type": "display_data"}], "source": "display(train_set.shape, valid_set.shape, test_set.shape)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment V1</b>\n\nGood job!\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "# 3. Investigate the quality of different models by changing hyperparameters."}, {"cell_type": "code", "execution_count": 67, "metadata": {"trusted": false}, "outputs": [], "source": "# creating features and targets for date sets\nfeatures_train = train_set.drop('is_ultra', axis=1)\ntarget_train = train_set['is_ultra']\nfeatures_valid = valid_set.drop('is_ultra', axis=1)\ntarget_valid = valid_set['is_ultra']\nfeatures_test = test_set.drop('is_ultra', axis=1)\ntarget_test = test_set['is_ultra']"}, {"cell_type": "markdown", "metadata": {}, "source": "## Decision Tree Classifier"}, {"cell_type": "code", "execution_count": 50, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "1 0.7542768273716952\n2 0.7822706065318819\n3 0.7853810264385692\n4 0.7791601866251944\n5 0.7791601866251944\n6 0.7838258164852255\n7 0.7822706065318819\n8 0.7791601866251944\n9 0.7822706065318819\nFinal depth= 3 with accuracy: 0.7853810264385692\n"}], "source": "# Runing decision trees with depth 1-10 to find the best accuracy.\nfinal_depth = 0\nfinal_score = 0\nfor depth in range(1, 10):\n    dtc_model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n    dtc_model.fit(features_train,target_train)\n    #valid_pred = dtc_model.predict(features_valid)  --- not necessary\n    accuracy = dtc_model.score(features_valid, target_valid)\n    print(depth, accuracy)\n    if accuracy > final_score:\n        final_depth = depth\n        final_score = accuracy\n\nprint(\"Final depth=\", final_depth,\"with accuracy:\",final_score)"}, {"cell_type": "code", "execution_count": 51, "metadata": {"trusted": false}, "outputs": [], "source": "# Assigning model hyperparameters\ndtc_model = DecisionTreeClassifier(random_state=12345, max_depth=3)"}, {"cell_type": "code", "execution_count": 36, "metadata": {"trusted": false}, "outputs": [], "source": "#training on the training set\ndtc_model = dtc_model.fit(features_train,target_train)"}, {"cell_type": "code", "execution_count": 37, "metadata": {"trusted": false}, "outputs": [{"data": {"text/plain": "0.8075726141078838"}, "execution_count": 37, "metadata": {}, "output_type": "execute_result"}], "source": "# Accuracy score for the training set\nstc_score_train = dtc_model.score(features_train, target_train)\nstc_score_train  "}, {"cell_type": "code", "execution_count": 40, "metadata": {"trusted": false}, "outputs": [{"data": {"text/plain": "0.7853810264385692"}, "execution_count": 40, "metadata": {}, "output_type": "execute_result"}], "source": "# Accuracy score for the validation set\nstc_score_valid = dtc_model.score(features_valid, target_valid)\nstc_score_valid  "}, {"cell_type": "markdown", "metadata": {}, "source": "The best Decision Tree Classifier model (depth=3) showed on the training set an accuracy of 80.7%, and on the validation set 78.5%."}, {"cell_type": "markdown", "metadata": {}, "source": "## Random Forest Classifier"}, {"cell_type": "code", "execution_count": 59, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Final estimators= 3 with accuracy: 0.7947122861586314\n"}], "source": "# Runing decision trees with depth 1-10 to find the best accuracy.\nfinal_est = 0\nfinal_score = 0\nfor est in range(1, 50):\n    rfc_model = RandomForestClassifier(random_state=12345, n_estimators=est)\n    rfc_model.fit(features_train,target_train)\n    accuracy = rfc_model.score(features_valid, target_valid)\n    #print(est, accuracy)\n    if accuracy > final_score:\n        final_est = est\n        final_score = accuracy\n\nprint(\"Final estimators=\", final_depth,\"with accuracy:\",final_score)"}, {"cell_type": "code", "execution_count": 60, "metadata": {"trusted": false}, "outputs": [], "source": "# Assigning model hyperparameters\nrfc_model = RandomForestClassifier(random_state=12345, n_estimators=3)"}, {"cell_type": "code", "execution_count": 61, "metadata": {"trusted": false}, "outputs": [], "source": "#training on the training set\nrfc_model = rfc_model.fit(features_train,target_train)"}, {"cell_type": "code", "execution_count": 62, "metadata": {"trusted": false}, "outputs": [{"data": {"text/plain": "0.9507261410788381"}, "execution_count": 62, "metadata": {}, "output_type": "execute_result"}], "source": "# Accuracy score for the training set\nrfc_score_train = rfc_model.score(features_train, target_train)\nrfc_score_train "}, {"cell_type": "code", "execution_count": 63, "metadata": {"trusted": false}, "outputs": [{"data": {"text/plain": "0.7387247278382582"}, "execution_count": 63, "metadata": {}, "output_type": "execute_result"}], "source": "# Accuracy score for the validation set\nrfc_score_valid = rfc_model.score(features_valid, target_valid)\nrfc_score_valid  "}, {"cell_type": "markdown", "metadata": {}, "source": "The best Random Forest Classifier (estimators=3) showed on the training set an accuracy of 95.1%, and on the validation set 73.8%.  \nI am not sure why I got that result on the validation set, when runing on the loop I got a different accuracy rate.  \nThe big difference in accuracy between the traingng and the validation set might indicade an overfitted model."}, {"cell_type": "markdown", "metadata": {}, "source": "## Logistic Regression"}, {"cell_type": "code", "execution_count": 73, "metadata": {"trusted": false}, "outputs": [], "source": "# Assigning model hyperparameters and training on the training set\nlr_model = LogisticRegression(random_state=12345, solver='liblinear')\nlr_model = lr_model.fit(features_train,target_train)"}, {"cell_type": "code", "execution_count": 75, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Logistic regression training score: 0.7589424572317263\n"}], "source": "# Accuracy score for the validation set\nscore = lr_model.score(features_valid, target_valid)\nprint(\"Logistic regression training score:\", score)"}, {"cell_type": "markdown", "metadata": {}, "source": "The Logistic Regression showed an accuracy of 75.9%."}, {"cell_type": "markdown", "metadata": {}, "source": "The best accuracy rate was on the Decision Tree Classifier."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment V1</b>\n\nEverything is correct. Well done!\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "# 4. Check the quality of the model using the test set."}, {"cell_type": "code", "execution_count": 74, "metadata": {"trusted": false}, "outputs": [], "source": "# Assigning model hyperparameters and testing on the test set\nfinal_model = DecisionTreeClassifier(random_state=12345, max_depth=3)\nfinal_model = final_model.fit(features_test, target_test)"}, {"cell_type": "code", "execution_count": 76, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Final modal testing set score: 0.7993779160186625\n"}], "source": "# Accuracy score for the test set\nscore = final_model.score(features_test, target_test)\nprint(\"Final modal testing set score:\", score)"}, {"cell_type": "markdown", "metadata": {}, "source": "I would like to do the edditional task but couldn't understand it. What is the meaning in ssnity check?"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment V1</b>\n\nGreat work!\n\nTo do a sanity check you need to compare the quality of your best ML model with the quality of the best constant model. If the quality of your ML model is less than the constant model, it means you ML model is useless.\n    \n</div>"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": false}, "outputs": [], "source": ""}], "metadata": {"ExecuteTimeLog": [{"duration": 8, "start_time": "2025-05-09T15:04:36.221Z"}, {"duration": 157, "start_time": "2025-05-09T15:06:21.181Z"}, {"duration": 332, "start_time": "2025-05-09T15:06:39.851Z"}, {"duration": 18, "start_time": "2025-05-09T15:06:41.680Z"}, {"duration": 34, "start_time": "2025-05-09T15:07:17.248Z"}, {"duration": 3, "start_time": "2025-05-09T15:07:21.481Z"}, {"duration": 17, "start_time": "2025-05-09T15:07:39.856Z"}, {"duration": 9, "start_time": "2025-05-09T15:07:47.273Z"}, {"duration": 485, "start_time": "2025-05-09T15:09:56.936Z"}, {"duration": 49, "start_time": "2025-05-09T15:13:36.954Z"}, {"duration": 5, "start_time": "2025-05-09T15:14:05.889Z"}, {"duration": 5, "start_time": "2025-05-09T15:14:34.742Z"}, {"duration": 5, "start_time": "2025-05-09T15:14:55.436Z"}, {"duration": 4, "start_time": "2025-05-09T15:15:21.452Z"}, {"duration": 3, "start_time": "2025-05-09T15:15:48.536Z"}, {"duration": 5, "start_time": "2025-05-09T15:17:51.801Z"}, {"duration": 4, "start_time": "2025-05-09T15:19:54.488Z"}, {"duration": 3, "start_time": "2025-05-09T15:20:25.987Z"}, {"duration": 18, "start_time": "2025-05-09T15:21:49.014Z"}, {"duration": 16, "start_time": "2025-05-09T15:21:55.190Z"}, {"duration": 15, "start_time": "2025-05-09T15:22:34.095Z"}, {"duration": 15, "start_time": "2025-05-09T15:22:54.845Z"}, {"duration": 4, "start_time": "2025-05-09T15:23:37.139Z"}, {"duration": 4, "start_time": "2025-05-09T15:24:34.852Z"}, {"duration": 28, "start_time": "2025-05-09T15:24:49.846Z"}, {"duration": 3, "start_time": "2025-05-09T15:26:00.622Z"}, {"duration": 11, "start_time": "2025-05-09T15:26:21.902Z"}, {"duration": 6, "start_time": "2025-05-09T15:27:03.615Z"}, {"duration": 6, "start_time": "2025-05-09T15:27:41.665Z"}, {"duration": 5, "start_time": "2025-05-09T15:28:20.880Z"}, {"duration": 5, "start_time": "2025-05-09T15:28:24.433Z"}, {"duration": 58, "start_time": "2025-05-09T15:29:59.917Z"}, {"duration": 47, "start_time": "2025-05-09T15:30:12.706Z"}, {"duration": 48, "start_time": "2025-05-09T15:32:02.412Z"}, {"duration": 2, "start_time": "2025-05-09T15:33:45.598Z"}, {"duration": 6, "start_time": "2025-05-09T15:33:48.326Z"}, {"duration": 5, "start_time": "2025-05-09T15:33:50.991Z"}, {"duration": 6, "start_time": "2025-05-09T15:33:52.843Z"}, {"duration": 3, "start_time": "2025-05-09T15:35:22.890Z"}, {"duration": 6, "start_time": "2025-05-09T15:37:07.977Z"}, {"duration": 8, "start_time": "2025-05-09T15:38:54.560Z"}, {"duration": 3859, "start_time": "2025-05-09T15:40:48.303Z"}, {"duration": 3804, "start_time": "2025-05-09T15:41:13.931Z"}, {"duration": 3781, "start_time": "2025-05-09T15:41:37.550Z"}, {"duration": 3817, "start_time": "2025-05-09T15:41:43.113Z"}, {"duration": 47, "start_time": "2025-05-09T15:42:38.034Z"}, {"duration": 3861, "start_time": "2025-05-09T15:44:03.893Z"}, {"duration": 3830, "start_time": "2025-05-09T15:44:12.734Z"}, {"duration": 47, "start_time": "2025-05-09T15:44:39.082Z"}, {"duration": 3, "start_time": "2025-05-09T15:44:40.057Z"}, {"duration": 2, "start_time": "2025-05-09T15:45:50.532Z"}, {"duration": 2, "start_time": "2025-05-09T15:46:33.813Z"}, {"duration": 14, "start_time": "2025-05-09T15:46:35.213Z"}, {"duration": 8, "start_time": "2025-05-09T15:46:58.504Z"}, {"duration": 6, "start_time": "2025-05-09T15:47:17.690Z"}, {"duration": 3, "start_time": "2025-05-09T15:48:32.343Z"}, {"duration": 11, "start_time": "2025-05-09T15:49:50.863Z"}, {"duration": 3819, "start_time": "2025-05-09T15:51:55.935Z"}, {"duration": 2, "start_time": "2025-05-09T15:52:01.884Z"}, {"duration": 14, "start_time": "2025-05-09T15:52:07.031Z"}, {"duration": 7, "start_time": "2025-05-09T15:52:08.109Z"}, {"duration": 6, "start_time": "2025-05-09T15:52:10.163Z"}, {"duration": 3, "start_time": "2025-05-09T16:03:45.782Z"}, {"duration": 11, "start_time": "2025-05-09T16:05:05.176Z"}, {"duration": 20, "start_time": "2025-05-09T16:05:41.186Z"}, {"duration": 5, "start_time": "2025-05-09T16:06:08.421Z"}, {"duration": 5, "start_time": "2025-05-09T16:06:13.410Z"}, {"duration": 5, "start_time": "2025-05-09T16:06:39.041Z"}, {"duration": 5, "start_time": "2025-05-09T16:07:06.631Z"}, {"duration": 5, "start_time": "2025-05-09T16:08:01.126Z"}, {"duration": 8, "start_time": "2025-05-09T16:08:03.217Z"}, {"duration": 9, "start_time": "2025-05-09T16:08:32.297Z"}, {"duration": 4, "start_time": "2025-05-09T16:09:00.448Z"}, {"duration": 4, "start_time": "2025-05-09T16:09:16.669Z"}, {"duration": 9, "start_time": "2025-05-09T16:09:36.336Z"}, {"duration": 13, "start_time": "2025-05-09T16:17:08.273Z"}, {"duration": 9, "start_time": "2025-05-09T16:35:46.542Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}